import requests
from bs4 import BeautifulSoup
import pandas as pd
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
import datetime

nltk.download("vader_lexicon")
sia = SentimentIntensityAnalyzer()

# ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜
def get_naver_news():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    articles = []

    for item in soup.select("div.list_content a"):
        title = item.get_text().strip()
        link = "https://" + item["href"][7:]
        sentiment_score = sia.polarity_scores(title)["compound"]
        sentiment = "ê¸ì •" if sentiment_score > 0 else "ë¶€ì •" if sentiment_score < 0 else "ì¤‘ë¦½"

        articles.append({"title": title, "link": link, "sentiment": sentiment})

    if len(articles) == 0:
        print("âŒ í¬ë¡¤ë§ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìžˆìŠµë‹ˆë‹¤.")
    else:
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(articles)}ê°œì˜ ë‰´ìŠ¤ ìˆ˜ì§‘ë¨.")

    return articles

# ë°ì´í„° ì €ìž¥
def save_to_csv(data):
    if len(data) == 0:
        print("ðŸš¨ ì €ìž¥í•  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ì„ ë§Œë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    df = pd.DataFrame(data)
    today = datetime.date.today().strftime("%Y-%m-%d")
    filename = f"news_{today}.csv"
    df.to_csv(filename, index=False, encoding="utf-8")
    print(f"âœ… ì €ìž¥ ì™„ë£Œ: {filename}")
    return filename

if __name__ == "__main__":
    news = get_naver_news()
    save_to_csv(news)
